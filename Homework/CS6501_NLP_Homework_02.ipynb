{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8joq98nXQwdi"
      },
      "source": [
        "Submission Deadline: __October 20, 2023; 11:59 PM__\n",
        "\n",
        "A penalty will be applied for late submission. Please refer to the course policy for more detail.  \n",
        "\n",
        "## Instructions\n",
        "\n",
        "Please read the instructions carefully before you start working on the homework.\n",
        "\n",
        "- Please follow instructions and printed out the results as required. Keep the printed results and your implementation for grading purpose.\n",
        "    - The TAs will not run your code for grading purpose unless it is necessary. That means, you may lose some points if the printed results are not in the submitted file.\n",
        "- Submission should be via Canvas.\n",
        "    - If you use Google Colab for running the code, please download the file and submit it via Canvas once it's done.\n",
        "    - Submission via a Google Colab link will be considered as an invalid submission.\n",
        "- Please double check the submitted file once you upload it to Canvas.\n",
        "    - Students should be responsible for checking whether they submit the right files.\n",
        "    - Re-submission is not allowed once the deadline is passed.\n",
        "\n",
        "Also, if you missed the class lectures, please study the course materials first before working on the homework. It may save you some time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mbi1ud-6beud"
      },
      "source": [
        "# Homework 02 Word Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kga3AJlUbeuf"
      },
      "source": [
        "### Goal\n",
        "\n",
        "The **goal** of this homework is to provide an opportunity to build an end-to-end system.\n",
        "\n",
        "Specifically, we are going to build a word embedding system, that can\n",
        "\n",
        "1. Read and preprocess raw data\n",
        "2. Use two different ways (latent semantic analysis and skip-gram) to learn word embeddings\n",
        "3. Evaluate the quality of word embeddings using some intrinsic evaluation methods\n",
        "\n",
        "### Submission\n",
        "\n",
        "Your submission should only include this notebook file. Please keep **all the outputs** in your submission for grading. We will run the code only if we are not sure it is correct.\n",
        "\n",
        "### Dependency\n",
        "\n",
        "You will need the following package to finish this homework assignment\n",
        "\n",
        "- [spaCy](https://pypi.org/project/spacy/)\n",
        "- [fasttext](https://pypi.org/project/fasttext/)\n",
        "\n",
        "### Hint\n",
        "\n",
        "Search for the keyword `TODO` to find out which parts need your input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "foccJkL4beug",
        "outputId": "e277f800-4051-4285-f409-787b3db97d3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading ...\n",
            "Decompressing the file ...\n",
            "Archive:  embeddings.zip\n",
            "   creating: embeddings/\n",
            "  inflating: embeddings/imdb-small.txt  \n",
            "  inflating: embeddings/word-pairs.txt  \n",
            "Read 10000 sentences\n"
          ]
        }
      ],
      "source": [
        "# Download the data from course webpage\n",
        "import urllib.request\n",
        "from os.path import isfile\n",
        "if not isfile(\"embeddings/imdb-small.txt\"):\n",
        "    url = \"https://yangfengji.net/uva-nlp-grad/data/embeddings.zip\"\n",
        "    print(\"Downloading ...\")\n",
        "    filename, headers = urllib.request.urlretrieve(url, filename=\"embeddings.zip\")\n",
        "\n",
        "    print(\"Decompressing the file ...\")\n",
        "    !unzip embeddings.zip\n",
        "\n",
        "sents = open(\"embeddings/imdb-small.txt\").read().split(\"\\n\")\n",
        "print(\"Read {} sentences\".format(len(sents)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0C2HysKMbeuh"
      },
      "source": [
        "## 1. Data Processing (5 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gv9x86d-beuh"
      },
      "source": [
        "Data processing is an **essential** skill for NLP researchers. Unlike machine learning where researchers sometimes may want to use synthetic data to demonstrate the potential of their algorithms, NLP researchers need to deal with real-world data all the time. Unfortunately, this means that these data are noisy and often contain irregular patterns. Therefore, a reasonable data processing can alleviate the challenge of building NLP systems to some extent and may also help boost the performance of machine learning models.\n",
        "\n",
        "Data processing for learning word embeddings includes two basic modules\n",
        "\n",
        "- Tokenizing texts and replacing some special tokens\n",
        "- Filtering low-frequency and building a vocab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqAnj84Tbeuh"
      },
      "source": [
        "### 1.1 Tokenization (2 points)\n",
        "\n",
        "The following function *tokenize()* should include the following components\n",
        "\n",
        "1. Load the raw text from the file named **imdb-small.txt**\n",
        "2. Convert all characters into lower cases\n",
        "3. Tokenize the raw text using `nltk.tokenize`\n",
        "4. Remove all punctuation (as single tokens) and replace all numbers with a special token `<num>`\n",
        "5. Write the preprocessed text to the file named **imdb-small.txt.tokenized** and maintain the same format (one paragraph per line)\n",
        "\n",
        "(The file names are pre-defined, please do not change them.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NQ9dtItlbeuh"
      },
      "outputs": [],
      "source": [
        "# TODO: add necessary packages here\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "\n",
        "def tokenize(infname=\"embeddings/imdb-small.txt\"):\n",
        "    outfname = open(infname + \".tokenized\", \"w\")\n",
        "\n",
        "    # ----------------------------------------\n",
        "    # TODO: add your code here\n",
        "    # convert all characters to lower case\n",
        "    with open(infname, \"r\") as file:\n",
        "      # tokenize the raw text via nltk.tokenize\n",
        "      nltk.download(\"punkt\")\n",
        "      # remove punctuation as single tokens\n",
        "      tokenizer = RegexpTokenizer(r'\\w+')\n",
        "\n",
        "      # we can do it this way\n",
        "      for line in file:\n",
        "        line = line.lower()\n",
        "        line_tokens = []\n",
        "        tokens = word_tokenize(line)\n",
        "        for token in tokens:\n",
        "          if token.isnumeric():\n",
        "            line_tokens.append(\"<num>\")\n",
        "          else:\n",
        "            line_tokens.extend(tokenizer.tokenize(token))\n",
        "\n",
        "      # or we can do it this way:\n",
        "      # for line in file:\n",
        "      #     line = line.lower()\n",
        "      #     line_tokens = []\n",
        "      #     tokens = word_tokenize(line)\n",
        "      #     for token in tokens:\n",
        "      #       line_tokens.extend(tokenizer.tokenize(token))\n",
        "\n",
        "      #     line_tokens = [\"<num>\" if item.isnumeric() else item for item in line_tokens]\n",
        "\n",
        "\n",
        "        cleaned_text = \" \".join(line_tokens)\n",
        "        outfname.write(\"{}\\n\".format(cleaned_text))\n",
        "\n",
        "    # ----------------------------------------\n",
        "    outfname.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-yYsfWmbeui"
      },
      "source": [
        "### 1.2 Filtering (2 points)\n",
        "\n",
        "The following function *token_filter()* should include the following components\n",
        "\n",
        "1. Remove the words that appear in the data less than 5 times (word_frequency < 5)\n",
        "2. Write the filtered data to the file named **imdb-small.txt.filtered** and maintain the same format (one sentence per line)\n",
        "3. Return a Python list that contains all the words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N72gHBoj-osC"
      },
      "source": [
        "Slight issue: the token <num> is converted into < num >"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bcWBcJoSbeui"
      },
      "outputs": [],
      "source": [
        "# TODO: add necessary packages here\n",
        "from nltk.probability import FreqDist\n",
        "from collections import Counter\n",
        "\n",
        "def token_filter(infname=\"embeddings/imdb-small.txt.tokenized\", thresh=5):\n",
        "    outfname = open(infname.replace(\".tokenized\", \".filtered\"), 'w')\n",
        "    # vocab = []\n",
        "\n",
        "    # ----------------------------------------\n",
        "    # TODO: remove \"pass\" and add your code here\n",
        "    # remove words that appear less than 5 times\n",
        "    with open(infname, \"r\") as file:\n",
        "      content = file.read()\n",
        "\n",
        "      # print(tokens)\n",
        "      word_freq = Counter(content.split(\" \"))\n",
        "      common_words = [word for word in word_freq if word_freq[word] >= thresh]\n",
        "      print(common_words[0:10])\n",
        "\n",
        "    with open(infname, \"r\") as file:\n",
        "      for line in file:\n",
        "        # line_tokens = word_tokenize(line)\n",
        "        filtered_tokens = [word for word in line.split(\" \") if word_freq[word] >= thresh]\n",
        "        cleaned_line = \" \".join(filtered_tokens)\n",
        "        outfname.write(\"{}\\n\".format(cleaned_line))\n",
        "\n",
        "    # return a python list with all the words\n",
        "\n",
        "    # ----------------------------------------\n",
        "    outfname.close()\n",
        "    # return vocab\n",
        "    return common_words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CZox3VFbeui"
      },
      "source": [
        "### 1.3 Put all together (1 point)\n",
        "\n",
        "The following code block will call the previous two functions to do data preprocessing.\n",
        "\n",
        "This code block should include the following steps\n",
        "\n",
        "- tokenization\n",
        "- build the vocabulary with the variable name `vocab`\n",
        "- print out the size of the vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syFxe2uobeui",
        "outputId": "11cd680e-d55c-4876-b7e8-b0f610498203"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['one', 'of', 'the', 'other', 'reviewers', 'has', 'mentioned', 'that', 'after', 'watching']\n",
            "The vocab size = 18445\n"
          ]
        }
      ],
      "source": [
        "tokenize()\n",
        "vocab = token_filter()\n",
        "print(\"The vocab size = {}\".format(len(vocab)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMVhCnpsbeui"
      },
      "source": [
        "## 2. Word Embeddings (5 points)\n",
        "\n",
        "In this section, you need to implement two different ways of constructing word embeddings: latent semantic analysis  and skipgram."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptLnV4mHbeuj"
      },
      "source": [
        "### 2.1 Latent semantic analysis (3 points)\n",
        "\n",
        "The function of LSA should include the following components\n",
        "\n",
        "- Construct the word-doc matrix using `CountVectorizer` with `tokenizer=lambda x : x.split()`, make sure in this matrix that each row represents one word and each column represents one document (sentence, to be accurate in this case)\n",
        "- Use the `TruncatedSVD` from `sklearn.decomposition` to factorize the word-doc matrix\n",
        "- Construct the word embedding matrix with dimensionality as $v \\times k$, where $v$ is the vocab size and $k$ is the word embedding dimension\n",
        "\n",
        "The LSA() function should return\n",
        "\n",
        "- **embeddings**: A matrix with size $v\\times k$ that contains all the word embeddings\n",
        "- **vocab**: A Python dict with size $v$ that maps a word to the corresponding word index. Please pay attention to the mapping relation in vocab, which will be needed in the evaluation section."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5zI4dJnFbeuj"
      },
      "outputs": [],
      "source": [
        "# TODO: add necessary packages here\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "def LSA(fname = \"embeddings/imdb-small.txt.filtered\", dim=50):\n",
        "    sents = open(fname).read().split(\"\\n\")\n",
        "\n",
        "    # -------------------------------------\n",
        "    # TODO: add your code here\n",
        "    # construct the word-doc matrix using CountVectorizer with tokenizer=lambda x : x.split()\n",
        "    # ensure that in this matrix, ecah row represents a word and each col represents a doc (sentence)\n",
        "    vectorizer = CountVectorizer(tokenizer=lambda x: x.split())\n",
        "\n",
        "    # okay so vectorizer.vocabulary_ gives us the mapping from word to matrix index\n",
        "    # and fit_transform gets us the matrix\n",
        "    embeddings = vectorizer.fit_transform(sents)\n",
        "    # print(vectorizer.get_feature_names_out()[0:20])\n",
        "    print(embeddings.shape)\n",
        "    # need to transpose embeddings so that we can get the words on rows and setnences in columns. Currently, the columns are words and rows are sentences\n",
        "    embeddings = embeddings.T\n",
        "    print(embeddings.shape)\n",
        "\n",
        "    svd = TruncatedSVD(n_components=dim)\n",
        "\n",
        "\n",
        "    # construct the word embedding matrix with dim v x k where v is vocab size nad k is word embedding dim\n",
        "    embeddings = svd.fit_transform(embeddings)\n",
        "    vocab = vectorizer.vocabulary_\n",
        "\n",
        "    # -------------------------------------\n",
        "    return embeddings, vocab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v17bhMzSbeuj"
      },
      "source": [
        "### 2.2 Skip-gram model (2 points)\n",
        "\n",
        "In this section, you do not have to implement the skip-gram model by yourself. An authentic implementation of skip-gram can be found in the Python package [fasttext](https://pypi.org/project/fasttext/), which you can install on the your local machine with the folllwing commandline or directly load the package if you are using Google Colab.\n",
        "```python\n",
        "pip install fasttext\n",
        "```\n",
        "\n",
        "In the following code, please use the `fasttext.train_unsupervised` function for the skipgram() implementation. For the `fasttext.train_unsupervised`, please use the following configurations\n",
        "\n",
        "- `model='skipgram'`\n",
        "- Context window size: `ws = 3`\n",
        "- Word embedding dimension: `dim = 50`\n",
        "- Number of negative examples: `neg = 5`\n",
        "\n",
        "For all other parameters, use their default values.\n",
        "\n",
        "Similar to the previous LSA(), Skipgram() should return\n",
        "\n",
        "- **embeddings**: A matrix with size $v\\times k$ that contains all the word embeddings\n",
        "- **vocab**: A Python dict with size $v$ that maps an index to the corresponding word\n",
        "\n",
        "To get the word embeddings and vocab from fasttext, you need to understand [some functions](https://pypi.org/project/fasttext/#api) provided by the `model` object in the fasttext."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1DZC1oDExyZ",
        "outputId": "674f04eb-9e0e-4d7b-b525-e6139a313e59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.2.tar.gz (68 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/68.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m61.4/68.8 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.8/68.8 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pybind11>=2.2 (from fasttext)\n",
            "  Using cached pybind11-2.11.1-py3-none-any.whl (227 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fasttext) (67.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fasttext) (1.23.5)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp310-cp310-linux_x86_64.whl size=4199771 sha256=a8d85a90fe56a5df93749819f568dfe5b6aa673711e6ab9ca327aaf06a775e0e\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/13/75/f811c84a8ab36eedbaef977a6a58a98990e8e0f1967f98f394\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.2 pybind11-2.11.1\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "if \"fasttext\" in sys.modules:\n",
        "  print(\"installed\")\n",
        "else:\n",
        "  !pip install fasttext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "cQ0arCTEbeuj"
      },
      "outputs": [],
      "source": [
        "# # TODO: add necessary packages here\n",
        "# import fasttext\n",
        "\n",
        "# def Skipgram(fname = \"embeddings/imdb-small.txt.filtered\", ws=3, dim=50):\n",
        "#     # ------------------------------------------\n",
        "#     # TODO: add your code here\n",
        "#     model = fasttext.train_unsupervised(fname, model='skipgram', ws=ws, dim=dim, neg=5)\n",
        "#     # print(model.get_dimension)\n",
        "#     embeddings = model.get_input_matrix()\n",
        "\n",
        "\n",
        "#     # getting vocab\n",
        "#     words = model.get_words()\n",
        "\n",
        "#     vocab = {}\n",
        "\n",
        "#     for word in words:\n",
        "#       vocab[word] = model.get_word_id(word)\n",
        "#     # vocab = model.get_words()\n",
        "\n",
        "#     # ------------------------------------------\n",
        "#     return embeddings, vocab"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: add necessary packages here\n",
        "import fasttext\n",
        "\n",
        "def Skipgram(fname = \"embeddings/imdb-small.txt.filtered\", ws=3, dim=50):\n",
        "    # ------------------------------------------\n",
        "    # TODO: add your code here\n",
        "    model = fasttext.train_unsupervised(fname, model='skipgram', ws=ws, dim=dim, neg=5)\n",
        "\n",
        "    # getting vocab\n",
        "    words = model.get_words()\n",
        "    vocab = {}\n",
        "    embeddings = [None] * len(words)\n",
        "\n",
        "    for word in words:\n",
        "      embeddings[model.get_word_id(word)] = model.get_word_vector(word)\n",
        "      vocab[word] = model.get_word_id(word)\n",
        "\n",
        "    # ------------------------------------------\n",
        "    return embeddings, vocab"
      ],
      "metadata": {
        "id": "OLp-x9cZXYkn"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPy2ImAlbeuj"
      },
      "source": [
        "### 2.3 Put all together\n",
        "\n",
        "Run the following code blocks to get word embeddings from two different methods. It may take a couple of minutes to compute both embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ahi-Z01zbeuj",
        "outputId": "2503f03c-98dc-4880-d3a3-20cb7042f19f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 18312)\n",
            "(18312, 10000)\n"
          ]
        }
      ],
      "source": [
        "embeddings_lsa, vocab_lsa = LSA()\n",
        "embeddings_sg, vocab_sg = Skipgram()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKbl52S2beuj"
      },
      "source": [
        "The following code will serve as the sanity check that `vocab_lsa` and `vocab_sg` contain the same words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abTUwVVRbeuj",
        "outputId": "42569595-edb3-4797-95b7-c6ddd2caa2f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The word that only appear in one vocab: {'</s>'}\n"
          ]
        }
      ],
      "source": [
        "lsa_word_set = set([item[0] for item in vocab_lsa.items()])\n",
        "sg_word_set = set([item[0] for item in vocab_sg.items()])\n",
        "sym_diff = lsa_word_set.symmetric_difference(sg_word_set)\n",
        "\n",
        "if len(sym_diff) == 0:\n",
        "    print(\"vocab_lsa and vocab_sg contain the same words!\")\n",
        "else:\n",
        "    print(\"The word that only appear in one vocab: {}\".format(sym_diff))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lyl_XqYlbeuj"
      },
      "source": [
        "If the only word from the `symmetric_difference()` function is `</s>`, then your implementation should be fine. (`</s>` was added by `fasttext` automatically to the end of each text.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3av8qPGMbeuj"
      },
      "source": [
        "## 3. Evaluation (5 points)\n",
        "\n",
        "In this homework, we will only use intrinsic evaluation. Specifically, for a list of predefined word pairs with their similarity scores, the evaluation is to calculate the correlation between the predefined similarity scores and the cosine similarity scores based on word embeddings. The higher the correlation, the better the quality of word embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "xLlF2ZcBbeuk"
      },
      "outputs": [],
      "source": [
        "def load_wordpairs(fname = \"embeddings/word-pairs.txt\", vocab=vocab):\n",
        "    records = {}\n",
        "    with open(fname) as fin:\n",
        "        for line in fin:\n",
        "            items = line.strip().split(\",\")\n",
        "            if (items[1] in vocab) and (items[2] in vocab): # make sure both words in the vocab\n",
        "                records[(items[1],items[2])] = float(items[3])\n",
        "    print(\"Load {} pairs of words for evaluation\".format(len(records)))\n",
        "    return records"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CP9rT0Jfbeuk"
      },
      "source": [
        "### 3.1 Word similarity correlation (2 points)\n",
        "\n",
        "The purpose of this section is to implement the correlation function that compares the predefined scores and the scores computed by cosine similarity. The code of the correlation function is almost done, and the only thing left is the code for computing cosine similarity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Tazeb8dibeuk"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import pearsonr\n",
        "# TODO: Add necessary packages here\n",
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "\n",
        "def correlation(records, embeddings, vocab):\n",
        "    predefined_scores = []\n",
        "    cossim_scores = []\n",
        "    for (words, sim_score) in records.items():\n",
        "        predefined_scores.append(sim_score)\n",
        "        # ---------------------------------\n",
        "        # TODO: add your code here for computing the cossine similarity\n",
        "        #       between words[0] and words[1], and assign the value to variable \"score\"\n",
        "        v1 = embeddings[vocab[words[0]]]\n",
        "        v2 = embeddings[vocab[words[1]]]\n",
        "        score = dot(v1, v2)/(norm(v1) * norm(v2))\n",
        "        cossim_scores.append(score)\n",
        "        # ---------------------------------\n",
        "    corr = pearsonr(predefined_scores, cossim_scores)\n",
        "    return corr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzFS-wdnbeuk"
      },
      "source": [
        "Run the following code block to calculate the correlations between pre-defined similarity scores and the cosine similarity scores based on word embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzFQqamVbeuk",
        "outputId": "68fcac98-28f6-423b-fb78-40391883ec28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load 147 pairs of words for evaluation\n",
            "The correlation with the LSA embeddings = 0.17513518696789473 with p-value 0.03386286673335794\n",
            "The correlation with the SG embeddings = 0.3353329502546251 with p-value 3.2979695853904775e-05\n",
            "Skipgram is better than LSA\n"
          ]
        }
      ],
      "source": [
        "# assuming we need to populate records here:\n",
        "records = load_wordpairs()\n",
        "\n",
        "corr_lsa = correlation(records, embeddings_lsa, vocab_lsa)\n",
        "print(\"The correlation with the LSA embeddings = {} with p-value {}\".format(corr_lsa[0], corr_lsa[1]))\n",
        "corr_sg = correlation(records, embeddings_sg, vocab_sg)\n",
        "print(\"The correlation with the SG embeddings = {} with p-value {}\".format(corr_sg[0], corr_sg[1]))\n",
        "\n",
        "if corr_lsa[0] > corr_sg[0]:\n",
        "    print(\"LSA is better than Skip-gram\")\n",
        "elif corr_lsa[0] < corr_sg[0]:\n",
        "    print(\"Skipgram is better than LSA\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWOW0SZlbeuk"
      },
      "source": [
        "### 3.2 Analysis of context window size in Skipgram (3 points)\n",
        "\n",
        "With the correlation function, we can analyze the effect of different context window sizes in the Skipgram model. Specifically, please call the previous implementation\n",
        "\n",
        "- `Skipgram(fname, ws, dim=50)` with the context window size `ws` as 3, 6, 9, 12, 15\n",
        "- For each context window size, calculate the correlation using the function `correlation(records, embeddings, vocab)`\n",
        "- **Print out** the fives correlation scores in your final submission: one score per line with the following format\n",
        "<center> ws\\t correlation</center>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tv-wIFibeuk",
        "outputId": "ae098c03-abcc-4a07-ee8a-310bc375463d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\tPearsonRResult(statistic=0.3353329502546251, pvalue=3.2979695853904775e-05)\n",
            "6\tPearsonRResult(statistic=0.35810578905237, pvalue=8.454613381787837e-06)\n",
            "9\tPearsonRResult(statistic=0.3521101124495204, pvalue=1.2223608204379404e-05)\n",
            "12\tPearsonRResult(statistic=0.3709323959282852, pvalue=3.745798854434258e-06)\n",
            "15\tPearsonRResult(statistic=0.4119353529025369, pvalue=2.173413630854652e-07)\n"
          ]
        }
      ],
      "source": [
        "# TODO: add your code here\n",
        "wsizes = [3, 6, 9, 12, 15]\n",
        "correlations = []\n",
        "\n",
        "for ws in wsizes:\n",
        "  embeddings_sg, vocab_sg = Skipgram(ws=ws)\n",
        "  corr_sg = correlation(records, embeddings_sg, vocab_sg)\n",
        "  correlations.append(corr_sg)\n",
        "  print(\"{}\\t{}\".format(ws, corr_sg))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Sr9rmhRbeuk"
      },
      "source": [
        "Similar experiment can also be conducted on the parameter of negative examples `neg`, but it will not be included in this homework."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFdE9GjCmg7-",
        "outputId": "e169010e-d26d-4da4-90b5-0e900e8da8f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3, 6, 9, 12, 15]\n"
          ]
        }
      ],
      "source": [
        "print(wsizes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xchn9x9ysnRq",
        "outputId": "729d5e00-9c7b-41d6-d43a-f83c7756bc8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[PearsonRResult(statistic=0.3353329502546251, pvalue=3.2979695853904775e-05), PearsonRResult(statistic=0.35810578905237, pvalue=8.454613381787837e-06), PearsonRResult(statistic=0.3521101124495204, pvalue=1.2223608204379404e-05), PearsonRResult(statistic=0.3709323959282852, pvalue=3.745798854434258e-06), PearsonRResult(statistic=0.4119353529025369, pvalue=2.173413630854652e-07)]\n"
          ]
        }
      ],
      "source": [
        "print(correlations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "Eb2uCF6dbK9t",
        "outputId": "48e76f1c-2fd1-4ed3-e109-96ede3aaa62c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(wsizes, correlations, marker='o', linestyle='--', color='b')\n",
        "plt.xlabel('Window Size')\n",
        "plt.ylabel('Correlation')\n",
        "plt.title('Correlation vs Window Size')\n",
        "\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}